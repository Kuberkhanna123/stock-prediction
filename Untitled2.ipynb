{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtHlGavYzb7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "def get_mape(y_true, y_pred): \n",
        "    \"\"\"\n",
        "    Compute mean absolute percentage error (MAPE)\n",
        "    \"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "def train_pred_eval_model(X_train_scaled, \\\n",
        "                          y_train_scaled, \\\n",
        "                          X_test_scaled, \\\n",
        "                          y_test, \\\n",
        "                          col_mean, \\\n",
        "                          col_std, \\\n",
        "                          seed=100, \\\n",
        "                          n_estimators=100, \\\n",
        "                          max_depth=3, \\\n",
        "                          learning_rate=0.1, \\\n",
        "                          min_child_weight=1, \\\n",
        "                          subsample=1, \\\n",
        "                          colsample_bytree=1, \\\n",
        "                          colsample_bylevel=1, \\\n",
        "                          gamma=0):\n",
        "    '''\n",
        "    Train model, do prediction, scale back to original range and do \n",
        "    evaluation\n",
        "    Use XGBoost here.\n",
        "    Inputs\n",
        "        X_train_scaled     : features for training. Scaled to have \n",
        "                             mean 0 and variance 1\n",
        "        y_train_scaled     : target for training. Scaled to have \n",
        "                             mean 0 and variance 1\n",
        "        X_test_scaled      : features for test. Each sample is \n",
        "                             scaled to mean 0 and variance 1\n",
        "        y_test             : target for test. Actual values, not \n",
        "                             scaled\n",
        "        col_mean           : means used to scale each sample of \n",
        "                             X_test_scaled. Same length as \n",
        "                             X_test_scaled and y_test\n",
        "        col_std            : standard deviations used to scale each \n",
        "                             sample of X_test_scaled. Same length as \n",
        "                             X_test_scaled and y_test\n",
        "        seed               : model seed\n",
        "        n_estimators       : number of boosted trees to fit\n",
        "        max_depth          : maximum tree depth for base learners\n",
        "        learning_rate      : boosting learning rate (xgb’s “eta”)\n",
        "        min_child_weight   : minimum sum of instance weight(hessian) \n",
        "                             needed in a child\n",
        "        subsample          : subsample ratio of the training \n",
        "                             instance\n",
        "        colsample_bytree   : subsample ratio of columns when \n",
        "                             constructing each tree\n",
        "        colsample_bylevel  : subsample ratio of columns for each \n",
        "                             split, in each level\n",
        "        gamma              : minimum loss reduction required to make \n",
        "                             a further partition on a leaf node of \n",
        "                             the tree\n",
        "    Outputs\n",
        "        rmse               : root mean square error of y_test and \n",
        "                             est\n",
        "        mape               : mean absolute percentage error of \n",
        "                             y_test and est\n",
        "        est                : predicted values. Same length as y_test\n",
        "    '''\n",
        "    model = XGBRegressor(seed=model_seed,\n",
        "                         n_estimators=n_estimators,\n",
        "                         max_depth=max_depth,\n",
        "                         learning_rate=learning_rate,\n",
        "                         min_child_weight=min_child_weight,\n",
        "                         subsample=subsample,\n",
        "                         colsample_bytree=colsample_bytree,\n",
        "                         colsample_bylevel=colsample_bylevel,\n",
        "                         gamma=gamma)\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train_scaled)\n",
        "    \n",
        "    # Get predicted labels and scale back to original range\n",
        "    est_scaled = model.predict(X_test_scaled)\n",
        "    est = est_scaled * col_std + col_mean\n",
        "    # Calculate RMSE\n",
        "    rmse = math.sqrt(mean_squared_error(y_test, est))\n",
        "    mape = get_mape(y_test, est)\n",
        "    \n",
        "    return rmse, mape, est\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def get_preds_lin_reg(df, target_col, N, pred_min, offset):\n",
        "    \"\"\"\n",
        "    Given a dataframe, get prediction at each timestep\n",
        "    Inputs\n",
        "        df         : dataframe with the values you want to predict     \n",
        "        target_col : name of the column you want to predict\n",
        "        N          : use previous N values to do prediction\n",
        "        pred_min   : all predictions should be >= pred_min\n",
        "        offset     : for df we only do predictions for df[offset:]\n",
        "    Outputs\n",
        "        pred_list  : the predictions for target_col\n",
        "    \"\"\"\n",
        "    # Create linear regression object\n",
        "    regr = LinearRegression(fit_intercept=True)\n",
        "    pred_list = []\n",
        "    for i in range(offset, len(df['adj_close'])):\n",
        "        X_train = np.array(range(len(df['adj_close'][i-N:i]))) \n",
        "        y_train = np.array(df['adj_close'][i-N:i]) \n",
        "        X_train = X_train.reshape(-1, 1)     \n",
        "        y_train = y_train.reshape(-1, 1)\n",
        "        regr.fit(X_train, y_train)            # Train the model\n",
        "        pred = regr.predict(N)\n",
        "    \n",
        "        pred_list.append(pred[0][0])  \n",
        "    \n",
        "    # If the values are < pred_min, set it to be pred_min\n",
        "    pred_list = np.array(pred_list)\n",
        "    pred_list[pred_list < pred_min] = pred_min\n",
        "        \n",
        "    return pred_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}